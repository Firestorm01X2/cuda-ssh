#docker build -t cuda-ssh .
services:
  cuda_ssh:
    image: cuda-ssh  # Имя вашего Docker-образа
    # Включить доступ к GPU через NVIDIA Container Toolkit
    gpus: all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "22:22"  # Проброс порта 2222 на порт 22 внутри контейнера
    # runtime: nvidia  # Использование NVIDIA Runtime для GPU (для старых Docker)
    environment:
      # Указать требуемые возможности NVIDIA для CUDA и OpenCL
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Для OpenCL на NVIDIA достаточно compute+utility; graphics требуется только для графики
    restart: unless-stopped  # Перезапуск контейнера в случае сбоя
    volumes:
      # Используем именованный том вместо bind mount на Windows, чтобы работали права
      - home-data:/home
      # Локальные примеры монтируем read-only, чтобы их можно было синхронизировать в volume
      - ./examples:/mnt/examples-src:ro
      - ./superusers.txt:/run/secrets/superusers.txt:ro
      - ./users.txt:/run/secrets/users.txt:ro
    #environment:
      # Дополнительные переменные окружения, если нужно
    tty: true  # Включение псевдотерминала
volumes:
  home-data:
